{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ‘‘ RL and the $N$-Queen Problem\n",
    "### Viviana MÃ¡rquez\n",
    "#### June 27th, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "â€¢ It's a classical problem in combinatorics proposed in 1848.\n",
    "\n",
    "â€¢ People are still working on this problem as of today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "â€¢ **Question:** \n",
    "\n",
    "How many ways can you place $n$-queens in an $n \\times n$ chessboard so that no two queens threaten each other?\n",
    "\n",
    "<center><img src=\"https://qph.fs.quoracdn.net/main-qimg-04a0f0702f86ecb8931bdd75af9e9a55\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=1$\n",
    "\n",
    "<center><img src=\"images/1queen.png\"></center>\n",
    "\n",
    "<center><b>1 solution!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=2$\n",
    "\n",
    "<center><img src=\"images/2queens.png\"></center>\n",
    "\n",
    "<center><b>0 solutions!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=3$\n",
    "\n",
    "<center><img src=\"images/3queens.png\"></center>\n",
    "\n",
    "<center><b>0 solutions!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=4$\n",
    "\n",
    "<center><img src=\"images/4queens.png\"></center>\n",
    "\n",
    "<center><b>2 solutions!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Known solutions...\n",
    "\n",
    "<img src=\"images/all.png\">\n",
    "\n",
    "â€¢ Highest-order known solution as of today: $n=27$ [(more info here)](https://github.com/preusser/q27)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=8$\n",
    "\n",
    "<center><img src=\"images/queens.png\" height='0.1'></center>\n",
    "\n",
    "<center><b>92 solutions!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=8$\n",
    "\n",
    "<center><img src=\"images/queens.png\" height='0.1'></center>\n",
    "\n",
    "<center>92 solutions!</center><br>\n",
    "<center><b>Out of $\\binom{64}{8}$ possible boards!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: $n=8$\n",
    "\n",
    "<center><img src=\"images/queens.png\" height='0.1'></center>\n",
    "\n",
    "<center>92 solutions!</center><br>\n",
    "<center><b>Out of 4,426,165,368 possible boards!</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ”Ž Scope of this project:\n",
    "\n",
    "<br>\n",
    "<center>Find <it>a</it> solution (queen placement) using Reinforcement Learning.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The $n$-queens problem as a Reinforcement Learning problem:\n",
    "\n",
    "<br>\n",
    "<center><b>Research question:</b> Can I make a RL agent learn how to find solutions to the n-queen problem?</center>\n",
    "<br>\n",
    "\n",
    "â€¢ **Agent:** Machine\n",
    "\n",
    "â€¢ **Environment:** Chessboard\n",
    "\n",
    "â€¢ **State:** Placement of the queens\n",
    "\n",
    "â€¢ **Action:** Coordinates of the next queen to place\n",
    "\n",
    "â€¢ **Reward:** 1 for a valid placement, 0 for a non-valid placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class Queens():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.board = np.array([[\"*\" for _ in range(n)] for _ in range(n)])\n",
    "        self.state = [\"*\" for _ in range(n)]\n",
    "        self.available = np.array([[\"O\" for _ in range(n)] for _ in range(n)])\n",
    "        self.allowed_moves = list(zip(*np.where(self.available == \"O\")))\n",
    "    \n",
    "    def print_board(self):\n",
    "        \"\"\"\n",
    "        Print current state of the game.\n",
    "        \"\"\"\n",
    "        return print(pd.DataFrame(self.board))\n",
    "    \n",
    "    def print_available(self):\n",
    "        \"\"\"\n",
    "        Prints available places.\n",
    "        \"\"\"\n",
    "        return print(pd.DataFrame(self.available))\n",
    "    \n",
    "    def is_sol(self):\n",
    "        \"\"\"\n",
    "        Check if current state is a solution.\n",
    "        \"\"\"\n",
    "        diagonals = [self.board.diagonal(i) for i in range(-self.n+1,self.n)] + \\\n",
    "                    [self.board[::-1,:].diagonal(i) for i in range(-self.n+1,self.n)]\n",
    "        for d in diagonals:\n",
    "            if list(d).count(\"Q\") > 1:\n",
    "                return False\n",
    "        if \"*\" in self.state:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def put_queen(self,x,y):\n",
    "        \"\"\"\n",
    "        Place a queen\n",
    "        \"\"\"\n",
    "        if self.available[y][x] == \"X\": return \"Not a valid movement. Try again!\"\n",
    "        self.state[x] = y\n",
    "        self.board[y][x] = \"Q\"\n",
    "        self.update_available(x,y)\n",
    "        return self.print_board()\n",
    "    \n",
    "    def update_available(self,x,y):\n",
    "        self.available[y][x] = \"X\"\n",
    "        self.available[y,:] = \"X\"\n",
    "        self.available[:,x] = \"X\"\n",
    "        \n",
    "        aux = np.arange(self.n)\n",
    "        diag_1 = aux[::-1,None] == aux + self.n - y - x -1\n",
    "        diag_2 = aux[:,None] == aux + y - x\n",
    "        self.available[diag_1|diag_2] = \"X\"\n",
    "        self.allowed_moves = list(zip(*np.where(self.available == \"O\")))\n",
    "          \n",
    "    def random_board(self):\n",
    "        \"\"\"\n",
    "        Return a random placement of the queens.\n",
    "        \"\"\"\n",
    "        self.restart()\n",
    "        self.state = np.random.permutation(self.n)\n",
    "        for i,s in enumerate(self.state):\n",
    "            self.board[s][i] = \"Q\"\n",
    "        self.available[:,:] = \"X\"\n",
    "        self.allowed_moves = list(zip(*np.where(self.available == \"O\")))\n",
    "        return self.print_board()\n",
    "    \n",
    "    def random_movement(self):\n",
    "        \"\"\"\n",
    "        Place a queen at random.\n",
    "        \"\"\"\n",
    "        if len(self.allowed_moves)==0:\n",
    "            return \"No more moves allowed!\"\n",
    "        else:\n",
    "            x,y = random.choice(self.allowed_moves)\n",
    "            self.put_queen(y,x)\n",
    "            \n",
    "    def sequential_movement(self):\n",
    "        \"\"\"\n",
    "        Place the next available queen.\n",
    "        \"\"\"\n",
    "        if len(self.allowed_moves)==0:\n",
    "            return \"No more moves allowed!\"\n",
    "        else:\n",
    "            x,y = self.allowed_moves[0]\n",
    "            self.put_queen(y,x)\n",
    "            \n",
    "    def play(self,mode):\n",
    "        '''\n",
    "        Given a mode, place queens until there are not more options.\n",
    "        '''\n",
    "        self.restart()\n",
    "        print(\"*** NEW GAME ***\")\n",
    "        while len(self.allowed_moves)!=0:\n",
    "            mode()\n",
    "            print()\n",
    "        return game.is_sol()\n",
    "    \n",
    "    def restart(self):\n",
    "        \"\"\"\n",
    "        Restart the game.\n",
    "        \"\"\"\n",
    "        self.__init__(self.n)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Environment \n",
    "Chess board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game = Queens(8)\n",
    "game.print_board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# State\n",
    "Placement of the queens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.random_movement()\n",
    "game.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.random_movement()\n",
    "game.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Action\n",
    "Coordinates of the next queen to place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.print_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.allowed_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reward\n",
    "1 for a valid placement, 0 for a non-valid placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "game.is_sol()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ‘¾ Let's play (and learn)!\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://media1.tenor.com/images/1f84b096cbe1cc9f3763c803bb17e10e/tenor.gif?itemid=5878976\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ‘¾ Let's play (and learn)!\n",
    "\n",
    "â€¢ Two strategies: \n",
    "    - Random placement\n",
    "    - Sequential placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def strategies(trials=1_000):\n",
    "    strategies = [game.random_movement, game.sequential_movement] \n",
    "    outcomes = []\n",
    "    for strategy in strategies:\n",
    "        outcomes.append(sum([game.play(strategy) for _ in range(trials)]))\n",
    "    return outcomes,strategies\n",
    "\n",
    "def play_and_learn(n=4, trials=1_000):\n",
    "    game = Queens(n)\n",
    "    outcomes,st = strategies(trials)\n",
    "    result = f\"The best strategy is: {str(st[outcomes.index(max(outcomes))])[21:].split()[0]} with {max(outcomes)} points in {trials} trials!\"\n",
    "    return outcomes,st,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "outcomes,strategies,result = play_and_learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ¤” Reflection\n",
    "\n",
    "â€¢ Random placement performs better than sequential placement. \n",
    "\n",
    "â€¢ There is a reason this problem is usually solved with Backtracking.\n",
    "\n",
    "â€¢ What would happen if we mix backtracking + reinforcement learning? ðŸ¤¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ðŸ“š References\n",
    "\n",
    "â€¢ Lim, S., Son, K., Park, S., & Lee, S. (2005). The Improvement of Convergence Rate in n-Queen Problem Using Reinforcement learning. Journal of Korean Institute of Intelligent Systems.\n",
    "\n",
    "â€¢ PreuÃŸer, T. B., & Engelhardt, M. R. (2016). Putting Queens in Carry Chains, N o?27. Journal of Signal Processing Systems, 88(2), 185-201. doi:10.1007/s11265-016-1176-8\n",
    "\n",
    "â€¢ Russell, S. J., & Norvig, P. (2018). Artificial intelligence a modern approach. Boston: Pearson.\n",
    "\n",
    "â€¢ Spiering, B. (2019). Reinforcement Learning course @ USF. Retrieved from https://github.com/brianspiering/rl-course"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
